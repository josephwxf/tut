#!/usr/bin/python
# This Python file uses the following encoding: utf-8

"""
   bnf_parser.py -- 一个cli工具,帮助自动生成yacc文件的token声明.

   Usage: python bnf_parser.py -i input_file [-l lookup_file] [-p parser_file] [-a ahelp_file]

   -i 输入bnf文件
   -p 生成yacc文件的token声明
   -l 生成lex文件需要的关键词查找表，lookup.c
   -a 生成readline tab键自动补齐需要的关键词查找表，ahelp.c

"""

import sys
import getopt
import string
import re

token_list = [[] for x in range(26)]
var_list = [[] for x in range(26)]
help_row_list = [[] for x in range(512)]
help_col_list = [[] for x in range(64)]

"""
    命令行参数解析 
"""
def parser_argument(argv):

    try:
        opts, args = getopt.getopt(argv, "i:l:p:a:", ["input_file", "lookup_file", "parser_file", "ahelp_file"])
    except getopt.GetoptError:
        return "", "", "", ""

    input_file = ""
    lookup_file = ""
    parser_file = ""
    ahelp_file = ""

    for opt, arg in opts:
        if opt in ["-i", "--input_file"]:
            input_file = arg
        elif opt in ["-l", "--lookup_file"]:
            lookup_file = arg
        elif opt in ["-p", "--parser_file"]:
            parser_file = arg
        elif opt in ["-a", "--ahelp_file"]:
            ahelp_file = arg

    return (input_file, lookup_file, parser_file, ahelp_file)

def get_pure_word(pure_str, set_token, set_var):
    index = ord(pure_str[0]) - ord('a')
    if set_token and pure_str not in token_list[index]:
        token_list[index].append(pure_str)
    if set_var and pure_str not in var_list[index]:
        var_list[index].append(pure_str)

def parse_angle_quote(str):
    #print "token:%s is in angle quote" % (str)
    cut_str = str[1:len(str)-1]
    #print cut_str
    if cut_str.isalpha():
        get_pure_word(cut_str, 1, 1)
    else:
        get_pure_word(cut_str, 0, 1)

def parse_square_bracket(str):
    #print "token:%s is in square_bracket" % (str)
    cut_str = str[1:len(str)-1]
    #print cut_str
    if cut_str.isalpha():
        get_pure_word(cut_str, 1, 0)
    elif cut_str.find('=') != -1:
        #print "find = "
        split_str = cut_str.split('=')
        #print "with '=', split_str:", split_str
        get_pure_word(split_str[0], 1, 0)
        parse_square_bracket(split_str[1])
    elif cut_str.find('|') != -1:
        #print "find |"
        split_str = cut_str.split('|')
        for i in range(len(split_str)):
            sub_str = split_str[i]
            #print "sub_str:", sub_str
            if sub_str.isalpha():
                get_pure_word(sub_str, 1, 1)
            elif sub_str[0] == '<':
                var_str = re.findall('<[\w|_]*>', sub_str)
                #print "var_str:", var_str
                for j in range(len(var_str)):
                    parse_angle_quote(var_str[j])

def parser_input_file(input_file):
    fin = open(input_file, "r")
    textlist = fin.readlines()
    line_index = 0
    for line in textlist:
        strip_str = line.strip()
        if strip_str:
            #print strip_str
            split_str = strip_str.split(" ")
            #print split_str
            #help_row_list[line_index].append(str(len(split_str)))
            help_row_list[line_index] = help_row_list[line_index] + split_str
            index = 0
            for i in range(len(split_str)):
                if split_str[i].isalpha():
                    if split_str[i] not in help_col_list[i]:
                        help_col_list[i].append(split_str[i])
                    index = ord(split_str[i][0]) - ord('a')
                    if split_str[i] not in token_list[index]:
                        token_list[index].append(split_str[i])
                elif split_str[i][0] in ['[', '{']:
                    #print "token:%s" % (split_str[i])
                    parse_square_bracket(split_str[i])
                elif split_str[i][0] == '<':
                    #print "token:%s" % (split_str[i])
                    parse_angle_quote(split_str[i])
            line_index += 1

    fin.close()

def format_print(fout, token, match_len):
    blank_num = 20 - len(token)
    if fout is not None:
        fout.write('\n    { "%s",%s%s,%s%d },' % (token, ' '*blank_num, string.upper(token), ' '*blank_num, match_len))


"""
    自动生成 parser.y and lookup.c 
"""

def gen_lookup_parser_file(lookup_file, parser_file):
    if lookup_file != "":
        fout_lookup = open(lookup_file, "w")
        lookup_header = lookup_file + ".header"
        #print lookup_header
        flookup_header_in = open(lookup_header, "r")
        lookup_header_list = flookup_header_in.readlines()
        for lookup_header_line in lookup_header_list:
            fout_lookup.write('%s' % lookup_header_line)
        flookup_header_in.close()
    else:
        fout_lookup = None

    if parser_file != "" :
        fout_parser = open(parser_file, "w")
        parser_header = parser_file + ".header"
        #print parser_header
        fparser_header_in = open(parser_header, "r")
        parser_header_list = fparser_header_in.readlines()
        for parser_header_line in parser_header_list:
            fout_parser.write('%s' % parser_header_line)
        fparser_header_in.close()
    else:
        fout_parser = None

    if fout_lookup is not None:
        fout_lookup.write("token_ent token_table[] = {\n")

    for j in range(26):
        if j == (ord('a') - ord('a')):
            token_list[j].append("ack")
            token_list[j].append("association_ud1")
            token_list[j].append("association_ud2")
            token_list[j].append("association_ud3")
            token_list[j].append("association_ud4")
        elif j == (ord('c') - ord('a')):
            token_list[j].append("compound_ipv4")
            token_list[j].append("compound_ipv6")
            token_list[j].append("compound_ud")
            token_list[j].append("crc_16")
            token_list[j].append("crc_32")
            token_list[j].append("customer_rule_id")
        elif j == (ord('d') - ord('a')):
            token_list[j].append("dip")
            token_list[j].append("dport")
        elif j == (ord('e') - ord('a')):
            token_list[j].append("eos")
        elif j == (ord('f') - ord('a')):
            token_list[j].append("fatal")
            token_list[j].append("fin")
        elif j == (ord('g') - ord('a')):
            token_list[j].append("global_ud")
        elif j == (ord('i') - ord('a')):
            token_list[j].append("icmp")
            token_list[j].append("invalid_char")
            token_list[j].append("ip_pool")
            token_list[j].append("isis")
        elif j == (ord('k') - ord('a')):
            token_list[j].append("key")
        elif j == (ord('l') - ord('a')):
            token_list[j].append("l2")
            token_list[j].append("l3")
            token_list[j].append("l4")
        elif j == (ord('m') - ord('a')):
            token_list[j].append("maintainer")
            token_list[j].append("mask_ipv4")
            token_list[j].append("mask_ipv6")
            token_list[j].append("md5")
        elif j == (ord('n') - ord('a')):
            token_list[j].append("no_mask_rule")
	    token_list[j].append("no_shut")
        elif j == (ord('o') - ord('a')):
            token_list[j].append("ow3")
        elif j == (ord('p') - ord('a')):
            token_list[j].append("protocol")
            token_list[j].append("psh")
        elif j == (ord('r') - ord('a')):
            token_list[j].append("redirect_ip")
            token_list[j].append("redirect_vlan")
            token_list[j].append("routing_proto")
            token_list[j].append("rst")
        elif j == (ord('s') - ord('a')):
            token_list[j].append("sip")
            token_list[j].append("sport")
            token_list[j].append("ssh")
            token_list[j].append("syn")
            token_list[j].append("size")
            token_list[j].append("single_fiber")
        elif j == (ord('t') - ord('a')):
            token_list[j].append("table")
            token_list[j].append("tcpflag")
        elif j == (ord('u') - ord('a')):
            token_list[j].append("ud")
            token_list[j].append("ud0")
            token_list[j].append("ud1")
            token_list[j].append("ud2")
            token_list[j].append("ud3")
            token_list[j].append("ud4")
            token_list[j].append("ud5")
            token_list[j].append("ud6")
            token_list[j].append("ud7")
            token_list[j].append("ud8")
            token_list[j].append("ud9")
            token_list[j].append("ud10")
            token_list[j].append("ud11")
            token_list[j].append("ud12")
            token_list[j].append("ud13")
            token_list[j].append("ud14")
            token_list[j].append("ud15")
            token_list[j].append("ud16")
            token_list[j].append("ud17")
            token_list[j].append("ud18")
            token_list[j].append("ud19")
            token_list[j].append("ud20")
            token_list[j].append("ud21")
            token_list[j].append("ud22")
            token_list[j].append("ud23")
            token_list[j].append("ud24")
            token_list[j].append("ud25")
            token_list[j].append("ud26")
            token_list[j].append("ud27")
            token_list[j].append("ud28")
            token_list[j].append("ud29")
            token_list[j].append("ud30")
            token_list[j].append("ud31")
            token_list[j].append("ud32")
            token_list[j].append("ud33")
            token_list[j].append("ud34")
            token_list[j].append("ud35")
            token_list[j].append("urg")
        elif j == (ord('v') - ord('a')):
            token_list[j].append("vlan_pool")
        elif j == (ord('w') - ord('a')):
            token_list[j].append("win_offset")
            token_list[j].append("win_ud")
            token_list[j].append("win_width")
        elif j == (ord('x') - ord('a')):
            token_list[j].append("xge_lan")
            token_list[j].append("xge_wan")
        if token_list[j]:
            sorted_token_list = sorted(token_list[j])
            #print sorted_token_list
            #print "sorted_token_len:", len(sorted_token_list)
            match_len = 0
            if fout_parser is not None:
                fout_parser.write('%token')
            for k in range(len(sorted_token_list)):
                next_k = k + 1
                #print "k:%d next_k:%d" % (k, next_k)
                if next_k < len(sorted_token_list):
                    token = sorted_token_list[k]
                    next_token = sorted_token_list[next_k]
                    cur_token_len = len(token)
                    next_token_len = len(next_token)
                    index = 0
                    while (index < cur_token_len and index < next_token_len and token[index] == next_token[index]):
                        index += 1
                    #print "token_len:%d next_token_len:%d index:%d match_len:%d" % (cur_token_len, next_token_len, index, match_len)
                    if match_len > index:
                        format_print(fout_lookup, token, match_len)
                        match_len = index + 1
                    else:
                        if index == cur_token_len:
                            match_len = index
                        else:
                            match_len = index + 1
                        format_print(fout_lookup, token, match_len)
                        if index == cur_token_len:
                            match_len += 1
                else:
                    if match_len == 0:
                        match_len = match_len + 1
                    format_print(fout_lookup, sorted_token_list[k], match_len)

                if fout_parser is not None:
                    fout_parser.write(' %s' % (string.upper(sorted_token_list[k])))
            if fout_parser is not None:
                fout_parser.write('\n')

    if fout_lookup is not None:
        fout_lookup.write('\n    { NULL,%s0,%s0 }' % (' '*18, ' '*19))
    if fout_lookup is not None:
        fout_lookup.write('\n};\n')

    if fout_lookup is not None:
        lookup_footer = lookup_file + ".footer"
        #print lookup_footer
        flookup_footer_in = open(lookup_footer, "r")
        lookup_footer_list = flookup_footer_in.readlines()
        for lookup_footer_line in lookup_footer_list:
            fout_lookup.write('%s' % lookup_footer_line)
        flookup_footer_in.close()
        fout_lookup.close()

    if fout_parser is not None:
        parser_footer = parser_file + ".footer"
        #print parser_footer
        fparser_footer_in = open(parser_footer, "r")
        parser_footer_list = fparser_footer_in.readlines()
        for parser_footer_line in parser_footer_list:
            fout_parser.write('%s' % parser_footer_line)
        fparser_footer_in.close()
        fout_parser.close()

"""
    自动生成 ahelp.c
"""

def gen_ahelp_file_header(fp):
    fp.write('#include "my_parser.h"\n\n')
    fp.write('char *helplist[MAX_CMD_NUM][MAX_CMD_WORD_NUM] = {\n')

def gen_ahelp_file(ahelp_file):
    if ahelp_file != "":
        fout_ahelp = open(ahelp_file, "w")
    else:
        fout_ahelp = None

    if fout_ahelp is not None:
        gen_ahelp_file_header(fout_ahelp)

    cmd_len = 0
    for m in range(512):
        if help_row_list[m]:
            #print help_row_list[m]
            fout_ahelp.write('\t{')
            list = help_row_list[m]
            list_len = len(list)
            if list_len > cmd_len:
                cmd_len = list_len
            fout_ahelp.write('"%d"' % list_len)
            for num in range(list_len):
                if list[num].find('"') == -1:
                    fout_ahelp.write(', "%s"' % (list[num]))
                else:
                    replace_str = list[num].replace(r'"', r'\"')
                    #print replace_str
                    fout_ahelp.write(', "%s"' % replace_str)
            if fout_ahelp is not None:
                fout_ahelp.write('},\n')
    if fout_ahelp is not None:
        fout_ahelp.write('};\n\n')

    if fout_ahelp is not None:
        fout_ahelp.write('char *tokenlist[MAX_CMD_WORD_NUM][MAX_CMD_NUM] = {\n')
    for k in range(cmd_len):
        #if help_col_list[k]:
            #print help_col_list[k]
            fout_ahelp.write('\t{')
            list = help_col_list[k]
            list_len = len(list)
            fout_ahelp.write('"%d"' % list_len)
            for num in range(list_len):
                if fout_ahelp is not None:
                    fout_ahelp.write(', "%s"' % (list[num]))
                if ( (num+1) % 6 ) ==  0 :
                    fout_ahelp.write("\n\t\t")
                    
            if fout_ahelp is not None:
                fout_ahelp.write('},\n')
    if fout_ahelp is not None:
        fout_ahelp.write('};\n')

    if fout_ahelp is not None:
        fout_ahelp.close()

if __name__ == '__main__':

    input_file, lookup_file, parser_file, ahelp_file = parser_argument(sys.argv[1:])
    #print input_file
    if input_file != "":
        parser_input_file(input_file)
    else:
        sys.stderr.write(__doc__)
        sys.exit(1)

    #print lookup_file
    #print parser_file
    if lookup_file != "" or parser_file != "":
        gen_lookup_parser_file(lookup_file, parser_file)

    #print ahelp_file
    if ahelp_file != "":
        gen_ahelp_file(ahelp_file)

# vim:expandtab
